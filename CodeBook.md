# ğŸ“– Codebook: Stand-up Comedy Transcript Analysis  

## 1ï¸âƒ£ Dataset Overview  
This dataset consists of **transcripts from 20 stand-up comedians**, scraped from [Scraps from the Loft](https://scrapsfromtheloft.com/stand-up-comedy-transcripts/). It is used to analyze vocabulary, common words, and profanity usage across different comedians.  

## 2ï¸âƒ£ Variables & Features  

### **ğŸ”¹ Raw Data Variables**
- **comedians** â€“ Name of the stand-up comedian.  
- **transcript** â€“ Full text of their stand-up routine. 
- **transcripts** â€“ Dictionary Containing Transcript of all Comics(keys).    

### **ğŸ”¹ Processed Data Variables**  
- **cleaned_transcript** â€“ Text after removing special characters and extra spaces.  
- **word_count** â€“ Total number of words in the transcript.  
- **unique_words** â€“ Number of unique words used.  
- **f_word_count** â€“ Number of times the comedian used the **F-word**.  
- **s_word_count** â€“ Number of times the comedian used the **S-word**.  
- **one_hot_encoding** â€“ A binary matrix representing the presence of words in the transcript.  
- **Pickling** was used to **store and reload processed data efficiently**.
- 
---

## 3ï¸âƒ£ Data Cleaning & Processing  
- **Regular Expressions** were used to remove unwanted characters, punctuation, and extra spaces.  
- **One-Hot Encoding** was applied to convert words into binary format for analysis.  
- **WordCloud** was generated to visualize frequently used words.  
- **Stop Words Removal** was performed to filter out common words like *the, is, and*.  
- **Profanity Analysis** counted the occurrences of specific swear words.  

---

## 4ï¸âƒ£ Analysis Methods  
- **Word Frequency Analysis** to find the most used words by each comedian.  
- **WordCloud Visualization** for an overview of the comedianâ€™s vocabulary.  
- **Profanity Analysis** to determine how frequently each comedian uses explicit words.  

---

## 5ï¸âƒ£ Output Files  
- **corpus.pkl** â€“ Preprocessed transcripts after cleaning.
- **dtm.stop.pkl** â€“ Preprocessed transcripts after removing stopwords.  
- **wordclouds/** â€“ Folder containing WordCloud images for each comedian.  
- **profanity_counts.csv** â€“ A CSV file with the count of explicit words for each comedian.  
- **final_analysis.csv** â€“ Processed dataset with all extracted features.  

---

## ğŸ“Œ Notes  
- This analysis focuses only on text processing and does not account for **speech tone or delivery style**.  
- Stop words removal affects word frequency counts, so some common words are excluded.  
- The dataset is limited to publicly available transcripts, so coverage may vary.  

